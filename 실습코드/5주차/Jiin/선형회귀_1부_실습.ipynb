{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "선형회귀 1부 실습.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOyWyxiXOQ0C+qxG7/umFUB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KaggleStudy4th/4th_kaggle_study/blob/main/%EC%8B%A4%EC%8A%B5%EC%BD%94%EB%93%9C/5%EC%A3%BC%EC%B0%A8/Jiin/%EC%84%A0%ED%98%95%ED%9A%8C%EA%B7%80_1%EB%B6%80_%EC%8B%A4%EC%8A%B5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "Y6RAo-2D7RF4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "98bLk6ls6z-B"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#for reproducibility\n",
        "torch.manual_seed(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZlQmyp_7WAT",
        "outputId": "eea5890d-f321-47e6-c57b-fdcce1b69a1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f11858bf3d0>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## data"
      ],
      "metadata": {
        "id": "pS_9n0ys7csJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train=torch.FloatTensor([[1],[2],[3]])\n",
        "y_train=torch.FloatTensor([[1],[2],[3]])"
      ],
      "metadata": {
        "id": "zuM6FQ6B7bhr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train)\n",
        "print(y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmcqc8iv7kbn",
        "outputId": "e2c10137-90e9-4fc5-f5dd-07f620a8f18a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.],\n",
            "        [2.],\n",
            "        [3.]])\n",
            "torch.Size([3, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train)\n",
        "print(y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3sUVgzU7oAA",
        "outputId": "50b4a355-4d1c-4a99-c24e-70b5a3df0d92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.],\n",
            "        [2.],\n",
            "        [3.]])\n",
            "torch.Size([3, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Weight Initialization"
      ],
      "metadata": {
        "id": "vm7_4xO38VI7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#학습용 변수라는 것을 명시\n",
        "W=torch.zeros(1,requires_grad=True)\n",
        "print(W)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yBRJj6O8RTZ",
        "outputId": "f08517ad-8adf-4ea1-9eb0-cc19e151d706"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#학습용 변수라는 것을 명시\n",
        "b=torch.zeros(1,requires_grad=True)\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNmD_Nxy8Zi8",
        "outputId": "bda0e236-d6e1-45b6-96ed-db7932f427db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Weight Initialization"
      ],
      "metadata": {
        "id": "YpqF9hMd9kjb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "W=torch.zeros(1,requires_grad=True)\n",
        "print(W)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLhLZlll8dS5",
        "outputId": "18b95c55-e38f-4bfc-8725-2852ae9c36b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b=torch.zeros(1,requires_grad=True)\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yD5jxa_I9rHb",
        "outputId": "dd18586f-771b-4b02-f588-f7c34dda8ffb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hypothesis\n",
        "\n",
        "$$ H(x)=Wx+b $$"
      ],
      "metadata": {
        "id": "OZh3gNqh94Lg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hypothesis=x_train*W+b\n",
        "print(hypothesis)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4qa3Gx89uBu",
        "outputId": "0b469e88-275e-49b9-d171-41d620d9ae9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.],\n",
            "        [0.],\n",
            "        [0.]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cost\n",
        "\n",
        "$$ cost(W,b)=1m∑i=1m(H(x(i))−y(i))2 $$"
      ],
      "metadata": {
        "id": "0Sq_UH4Q_NtI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(hypothesis)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Ms2lw5o9_Vu",
        "outputId": "c1525cb6-8fec-474f-9ad4-e78a0f191552"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.],\n",
            "        [0.],\n",
            "        [0.]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZgcJEhuH_XH6",
        "outputId": "9a7aca34-405a-40b8-eb16-c89f4003ad84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.],\n",
            "        [2.],\n",
            "        [3.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(hypothesis-y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INDK5D0U_aC1",
        "outputId": "7aa23c13-9989-4935-ec8e-8b090a88d958"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-1.],\n",
            "        [-2.],\n",
            "        [-3.]], grad_fn=<SubBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print((hypothesis-y_train**2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKrH7hrh_tSx",
        "outputId": "872b2dfd-3458-4912-df4b-3156a7c9abd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-1.],\n",
            "        [-4.],\n",
            "        [-9.]], grad_fn=<SubBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cost=torch.mean((hypothesis-y_train)**2)\n",
        "print(cost)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZgCFAvsI_ysy",
        "outputId": "78715f14-172f-4142-92db-fb0912cd833a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(4.6667, grad_fn=<MeanBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gradient Descent"
      ],
      "metadata": {
        "id": "Cvpmf8sPBFMU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# learning rate => lr = 0.01\n",
        "# W := W - alpha*d/dw*cost(w)\n",
        "\n",
        "optimizer=optim.SGD([W,b],lr=0.01)#경사하강법 방식 SGD(직접 구현도 가능하지만 파이토치에 저장되어있음)"
      ],
      "metadata": {
        "id": "ZAyl1uJu_1sc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#옵티마이저 초기화\n",
        "optimizer.zero_grad()\n",
        "\n",
        "#cost 계산 !!! 미분값 계산해서\n",
        "cost.backward()\n",
        "#옵티마이저 갱신\n",
        "optimizer.step()"
      ],
      "metadata": {
        "id": "tpQ_mHRrBTxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(W)\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTgTOB_nBdSC",
        "outputId": "d8175c07-3d9d-426b-d9d5-701f4b303f46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.0933], requires_grad=True)\n",
            "tensor([0.0400], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hypothesis=x_train*W+b\n",
        "print(hypothesis)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxQwJGK_Beo5",
        "outputId": "8b6c70de-6aee-4dbb-eeae-51b501a50d48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1333],\n",
            "        [0.2267],\n",
            "        [0.3200]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cost=torch.mean((hypothesis-y_train)**2)\n",
        "print(cost)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SoNerwWVDLbm",
        "outputId": "77a68732-23eb-4dfb-b805-c07202d9fd8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(3.6927, grad_fn=<MeanBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training with full code\n"
      ],
      "metadata": {
        "id": "UmhypmMCDZ9Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터\n",
        "X_train=torch.FloatTensor([[1],[2],[3]])\n",
        "y_train=torch.FloatTensor([[1],[2],[3]])\n",
        "\n",
        "#모델 초기화\n",
        "W=torch.zeros(1,requires_grad=True)\n",
        "b=torch.zeros(1,requires_grad=True)\n",
        "\n",
        "#optimizer 설정\n",
        "optimizer=optim.SGD([W,b],lr=0.01)\n",
        "\n",
        "nb_epochs=1000\n",
        "for epoch in range(nb_epochs+1):\n",
        "\n",
        "  #H(x)계산\n",
        "  hypothesis=x_train*W+b\n",
        "\n",
        "  #cost 계산\n",
        "  cost=torch.mean((hypothesis-y_train)**2)\n",
        "\n",
        "  #cost로 H(x) 개선\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  #100번마다 로그 출력\n",
        "  if epoch%100==0:\n",
        "    print('Epoch {:4d}/{} W:{:.3f}, b: {:.3f} Cost:{:.6f}'.format(\n",
        "        epoch,nb_epochs,W.item(),b.item(),cost.item()\n",
        "    ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqXzsnf5DPnp",
        "outputId": "70ae2cca-d134-44da-96f1-532ca7ecabe4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/1000 W:0.093, b: 0.040 Cost:4.666667\n",
            "Epoch  100/1000 W:0.873, b: 0.289 Cost:0.012043\n",
            "Epoch  200/1000 W:0.900, b: 0.227 Cost:0.007442\n",
            "Epoch  300/1000 W:0.921, b: 0.179 Cost:0.004598\n",
            "Epoch  400/1000 W:0.938, b: 0.140 Cost:0.002842\n",
            "Epoch  500/1000 W:0.951, b: 0.110 Cost:0.001756\n",
            "Epoch  600/1000 W:0.962, b: 0.087 Cost:0.001085\n",
            "Epoch  700/1000 W:0.970, b: 0.068 Cost:0.000670\n",
            "Epoch  800/1000 W:0.976, b: 0.054 Cost:0.000414\n",
            "Epoch  900/1000 W:0.981, b: 0.042 Cost:0.000256\n",
            "Epoch 1000/1000 W:0.985, b: 0.033 Cost:0.000158\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# H(x) = Wx + b\n",
        "# 가설설정 => 예측하고자 하는 값 => 시험성적 => 1 * 7 + 0.033 = "
      ],
      "metadata": {
        "id": "26-jMyWLGPv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "0.985*9+0.033"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZbQs3HMF9cm",
        "outputId": "c60da0f0-c871-4bf0-df1c-9ae5b647643b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8.898"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 텐서플로우와 케라스로 선형회귀 구현하기"
      ],
      "metadata": {
        "id": "8xHAAVN7FsTg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. 자동 미분"
      ],
      "metadata": {
        "id": "rwo4WfuRFwkk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "q2JdnFTZGLI_"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "tape_gradient()는 자동 미분 기능을 수행합니다. 임의로 라는 식을 세워보고, 에 대해 미분해보겠습니다."
      ],
      "metadata": {
        "id": "Hg-hPh8pINtA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#임의로 2w^2+5라는 식을 세워보고 w에 대해 미분\n",
        "\n",
        "w=tf.Variable(2.)\n",
        "\n",
        "def f(w):\n",
        "  y=w**2\n",
        "  z=2*y+5\n",
        "  return z\n"
      ],
      "metadata": {
        "id": "C5pC3pbnFzQ7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.GradientTape() as tape:\n",
        "  z=f(w)\n",
        "\n",
        "gradients=tape.gradient(z,[w])\n",
        "print(gradients)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cVedNNTGYJp",
        "outputId": "e06fdc9c-dcf6-42a3-bbf6-e3450054b02e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[<tf.Tensor: shape=(), dtype=float32, numpy=8.0>]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. 자동 미분을 이용한 선형 회귀 구현\n",
        "\n",
        "가중치 변수 w와 b선언\n"
      ],
      "metadata": {
        "id": "GhrmY7g_IRoI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w=tf.Variable(4.0)\n",
        "b=tf.Variable(1.0)"
      ],
      "metadata": {
        "id": "wUelrLtFG0TV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#가설을 함수로 정의\n",
        "def hypothesis(x):\n",
        "  return w*x+b"
      ],
      "metadata": {
        "id": "1nOGW37aIZxP"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test=[3.5,5,5.5,6]\n",
        "print(hypothesis(x_test).numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmEczsuqId9o",
        "outputId": "adabd63b-d3b3-4207-8942-5777066c91ca"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15. 21. 23. 25.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#평균 제곱 오차를 손실함수로 정의\n",
        "def mse_loss(y_pred,y):\n",
        "  return tf.reduce_mean(tf.square(y_pred-y))\n",
        "  #두개의 차이값을 제곱해 평균"
      ],
      "metadata": {
        "id": "etG65qJHIh42"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = [1, 2, 3, 4, 5, 6, 7, 8, 9] # 공부하는 시간\n",
        "y = [11, 22, 33, 44, 53, 66, 77, 87, 95] # 각 공부하는 시간에 맵핑되는 성적"
      ],
      "metadata": {
        "id": "tUybdcTiIw-9"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#옵티마이저는 경사 하강법을 사용하되 학습률은 0.01을 사용 learning rate\n",
        "optimizer=tf.optimizers.SGD(0.01)"
      ],
      "metadata": {
        "id": "0d9UKXWFJDG3"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#300번에 걸쳐 경사 하강법 수행\n",
        "for i in range(301):\n",
        "  with tf.GradientTape() as tape:\n",
        "    #현재 파라미터에 기반한 입력 x에 대한 예측값을 y_pred\n",
        "    y_pred=hypothesis(x)\n",
        "    \n",
        "    #평균 제곱 오차를 계산\n",
        "    cost=mse_loss(y_pred,y)\n",
        "\n",
        "  #손실함수에 대한 파라미터의 미분값계산\n",
        "  gradients=tape.gradient(cost,[w,b])\n",
        "\n",
        "  #파라미터 업데이트\n",
        "  optimizer.apply_gradients(zip(gradients,[w,b]))\n",
        "\n",
        "  if i % 10 == 0:\n",
        "      print(\"epoch : {:3} | w의 값 : {:5.4f} | b의 값 : {:5.4} | cost : {:5.6f}\".format(i, w.numpy(), b.numpy(), cost))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kY4XF-F_JJRD",
        "outputId": "e4249170-6f44-4ece-ba39-615c05356ce4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch :   0 | w의 값 : 8.2133 | b의 값 : 1.664 | cost : 1402.555542\n",
            "epoch :  10 | w의 값 : 10.4971 | b의 값 : 1.977 | cost : 1.351182\n",
            "epoch :  20 | w의 값 : 10.5047 | b의 값 :  1.93 | cost : 1.328163\n",
            "epoch :  30 | w의 값 : 10.5119 | b의 값 : 1.884 | cost : 1.306966\n",
            "epoch :  40 | w의 값 : 10.5188 | b의 값 : 1.841 | cost : 1.287436\n",
            "epoch :  50 | w의 값 : 10.5254 | b의 값 : 1.799 | cost : 1.269459\n",
            "epoch :  60 | w의 값 : 10.5318 | b의 값 : 1.759 | cost : 1.252897\n",
            "epoch :  70 | w의 값 : 10.5379 | b의 값 : 1.721 | cost : 1.237644\n",
            "epoch :  80 | w의 값 : 10.5438 | b의 값 : 1.684 | cost : 1.223597\n",
            "epoch :  90 | w의 값 : 10.5494 | b의 값 : 1.648 | cost : 1.210658\n",
            "epoch : 100 | w의 값 : 10.5548 | b의 값 : 1.614 | cost : 1.198740\n",
            "epoch : 110 | w의 값 : 10.5600 | b의 값 : 1.582 | cost : 1.187767\n",
            "epoch : 120 | w의 값 : 10.5650 | b의 값 :  1.55 | cost : 1.177665\n",
            "epoch : 130 | w의 값 : 10.5697 | b의 값 :  1.52 | cost : 1.168354\n",
            "epoch : 140 | w의 값 : 10.5743 | b의 값 : 1.492 | cost : 1.159782\n",
            "epoch : 150 | w의 값 : 10.5787 | b의 값 : 1.464 | cost : 1.151890\n",
            "epoch : 160 | w의 값 : 10.5829 | b의 값 : 1.437 | cost : 1.144619\n",
            "epoch : 170 | w의 값 : 10.5870 | b의 값 : 1.412 | cost : 1.137924\n",
            "epoch : 180 | w의 값 : 10.5909 | b의 값 : 1.387 | cost : 1.131752\n",
            "epoch : 190 | w의 값 : 10.5946 | b의 값 : 1.364 | cost : 1.126073\n",
            "epoch : 200 | w의 값 : 10.5982 | b의 값 : 1.341 | cost : 1.120843\n",
            "epoch : 210 | w의 값 : 10.6016 | b의 값 :  1.32 | cost : 1.116026\n",
            "epoch : 220 | w의 값 : 10.6049 | b의 값 : 1.299 | cost : 1.111589\n",
            "epoch : 230 | w의 값 : 10.6081 | b의 값 : 1.279 | cost : 1.107504\n",
            "epoch : 240 | w의 값 : 10.6111 | b의 값 :  1.26 | cost : 1.103736\n",
            "epoch : 250 | w의 값 : 10.6140 | b의 값 : 1.242 | cost : 1.100273\n",
            "epoch : 260 | w의 값 : 10.6168 | b의 값 : 1.224 | cost : 1.097082\n",
            "epoch : 270 | w의 값 : 10.6195 | b의 값 : 1.207 | cost : 1.094143\n",
            "epoch : 280 | w의 값 : 10.6221 | b의 값 : 1.191 | cost : 1.091434\n",
            "epoch : 290 | w의 값 : 10.6245 | b의 값 : 1.176 | cost : 1.088940\n",
            "epoch : 300 | w의 값 : 10.6269 | b의 값 : 1.161 | cost : 1.086645\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "w와 b값이 계속 업데이트 됨에 따라서 cost가 지속적으로 줄어드는 것을 확인할 수 있습니다. 학습된 w와 b의 값에 대해서 임의 입력을 넣었을 경우의 예측값을 확인해봅시다."
      ],
      "metadata": {
        "id": "Zmnu8DDBKVwK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_test = [3.5, 5, 5.5, 6]\n",
        "print(hypothesis(x_test).numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIHYNyI0KNjp",
        "outputId": "3f892bd0-f78d-40d2-f2bb-52f0a6bfbe4a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[38.35479  54.295143 59.608593 64.92204 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. 케라스로 구현하는 선형 회귀"
      ],
      "metadata": {
        "id": "SHuubTcQLCl9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "x = [1, 2, 3, 4, 5, 6, 7, 8, 9] # 공부하는 시간\n",
        "y = [11, 22, 33, 44, 53, 66, 77, 87, 95] # 각 공부하는 시간에 맵핑되는 성적\n",
        "\n",
        "model=Sequential()\n",
        "\n",
        "model.add(Dense(1,input_dim=1,activation='linear'))\n",
        "\n",
        "sgd=optimizers.SGD(lr=0.01)\n",
        "\n",
        "#손실함수 ; 평균제곱오차 mse\n",
        "model.compile(optimizer=sgd,loss='mse',metrics=['mse'])\n",
        "\n",
        "#주어진 x와 y데이터에 대해서 오차를 최고화 하는 작업을 300번 시도\n",
        "model.fit(x,y,epochs=300)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NKSw9AdKXDE",
        "outputId": "6899d181-c77e-4292-e411-a6fa3c5b4bb6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 3397.8491 - mse: 3397.8491\n",
            "Epoch 2/300\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 419.1263 - mse: 419.1263\n",
            "Epoch 3/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 52.6159 - mse: 52.6159\n",
            "Epoch 4/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.5186 - mse: 7.5186\n",
            "Epoch 5/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.9688 - mse: 1.9688\n",
            "Epoch 6/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 1.2850 - mse: 1.2850\n",
            "Epoch 7/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 1.1999 - mse: 1.1999\n",
            "Epoch 8/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 1.1885 - mse: 1.1885\n",
            "Epoch 9/300\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.1862 - mse: 1.1862\n",
            "Epoch 10/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.1850 - mse: 1.1850\n",
            "Epoch 11/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.1840 - mse: 1.1840\n",
            "Epoch 12/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.1830 - mse: 1.1830\n",
            "Epoch 13/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 1.1820 - mse: 1.1820\n",
            "Epoch 14/300\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.1810 - mse: 1.1810\n",
            "Epoch 15/300\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.1800 - mse: 1.1800\n",
            "Epoch 16/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 1.1790 - mse: 1.1790\n",
            "Epoch 17/300\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 1.1780 - mse: 1.1780\n",
            "Epoch 18/300\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 1.1770 - mse: 1.1770\n",
            "Epoch 19/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 1.1761 - mse: 1.1761\n",
            "Epoch 20/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 1.1751 - mse: 1.1751\n",
            "Epoch 21/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.1742 - mse: 1.1742\n",
            "Epoch 22/300\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1732 - mse: 1.1732\n",
            "Epoch 23/300\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.1723 - mse: 1.1723\n",
            "Epoch 24/300\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1714 - mse: 1.1714\n",
            "Epoch 25/300\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1705 - mse: 1.1705\n",
            "Epoch 26/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.1696 - mse: 1.1696\n",
            "Epoch 27/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.1687 - mse: 1.1687\n",
            "Epoch 28/300\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 1.1678 - mse: 1.1678\n",
            "Epoch 29/300\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.1669 - mse: 1.1669\n",
            "Epoch 30/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.1660 - mse: 1.1660\n",
            "Epoch 31/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 1.1651 - mse: 1.1651\n",
            "Epoch 32/300\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1643 - mse: 1.1643\n",
            "Epoch 33/300\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.1634 - mse: 1.1634\n",
            "Epoch 34/300\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1626 - mse: 1.1626\n",
            "Epoch 35/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.1617 - mse: 1.1617\n",
            "Epoch 36/300\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1609 - mse: 1.1609\n",
            "Epoch 37/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.1601 - mse: 1.1601\n",
            "Epoch 38/300\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 1.1592 - mse: 1.1592\n",
            "Epoch 39/300\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.1584 - mse: 1.1584\n",
            "Epoch 40/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.1576 - mse: 1.1576\n",
            "Epoch 41/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.1568 - mse: 1.1568\n",
            "Epoch 42/300\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 1.1560 - mse: 1.1560\n",
            "Epoch 43/300\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1552 - mse: 1.1552\n",
            "Epoch 44/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.1545 - mse: 1.1545\n",
            "Epoch 45/300\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1537 - mse: 1.1537\n",
            "Epoch 46/300\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1529 - mse: 1.1529\n",
            "Epoch 47/300\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.1521 - mse: 1.1521\n",
            "Epoch 48/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.1514 - mse: 1.1514\n",
            "Epoch 49/300\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.1506 - mse: 1.1506\n",
            "Epoch 50/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.1499 - mse: 1.1499\n",
            "Epoch 51/300\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.1492 - mse: 1.1492\n",
            "Epoch 52/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.1484 - mse: 1.1484\n",
            "Epoch 53/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.1477 - mse: 1.1477\n",
            "Epoch 54/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.1470 - mse: 1.1470\n",
            "Epoch 55/300\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 1.1463 - mse: 1.1463\n",
            "Epoch 56/300\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.1456 - mse: 1.1456\n",
            "Epoch 57/300\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 1.1449 - mse: 1.1449\n",
            "Epoch 58/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 1.1442 - mse: 1.1442\n",
            "Epoch 59/300\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.1435 - mse: 1.1435\n",
            "Epoch 60/300\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.1428 - mse: 1.1428\n",
            "Epoch 61/300\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.1421 - mse: 1.1421\n",
            "Epoch 62/300\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.1414 - mse: 1.1414\n",
            "Epoch 63/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1408 - mse: 1.1408\n",
            "Epoch 64/300\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.1401 - mse: 1.1401\n",
            "Epoch 65/300\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.1394 - mse: 1.1394\n",
            "Epoch 66/300\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.1388 - mse: 1.1388\n",
            "Epoch 67/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 1.1381 - mse: 1.1381\n",
            "Epoch 68/300\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.1375 - mse: 1.1375\n",
            "Epoch 69/300\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.1369 - mse: 1.1369\n",
            "Epoch 70/300\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.1362 - mse: 1.1362\n",
            "Epoch 71/300\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.1356 - mse: 1.1356\n",
            "Epoch 72/300\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1350 - mse: 1.1350\n",
            "Epoch 73/300\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.1344 - mse: 1.1344\n",
            "Epoch 74/300\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1338 - mse: 1.1338\n",
            "Epoch 75/300\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.1332 - mse: 1.1332\n",
            "Epoch 76/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.1326 - mse: 1.1326\n",
            "Epoch 77/300\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.1320 - mse: 1.1320\n",
            "Epoch 78/300\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.1314 - mse: 1.1314\n",
            "Epoch 79/300\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 1.1308 - mse: 1.1308\n",
            "Epoch 80/300\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.1302 - mse: 1.1302\n",
            "Epoch 81/300\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1296 - mse: 1.1296\n",
            "Epoch 82/300\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.1291 - mse: 1.1291\n",
            "Epoch 83/300\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 1.1285 - mse: 1.1285\n",
            "Epoch 84/300\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1279 - mse: 1.1279\n",
            "Epoch 85/300\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1274 - mse: 1.1274\n",
            "Epoch 86/300\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1268 - mse: 1.1268\n",
            "Epoch 87/300\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.1263 - mse: 1.1263\n",
            "Epoch 88/300\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.1257 - mse: 1.1257\n",
            "Epoch 89/300\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1252 - mse: 1.1252\n",
            "Epoch 90/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.1246 - mse: 1.1246\n",
            "Epoch 91/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.1241 - mse: 1.1241\n",
            "Epoch 92/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.1236 - mse: 1.1236\n",
            "Epoch 93/300\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.1231 - mse: 1.1231\n",
            "Epoch 94/300\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.1225 - mse: 1.1225\n",
            "Epoch 95/300\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.1220 - mse: 1.1220\n",
            "Epoch 96/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 1.1215 - mse: 1.1215\n",
            "Epoch 97/300\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.1210 - mse: 1.1210\n",
            "Epoch 98/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.1205 - mse: 1.1205\n",
            "Epoch 99/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.1200 - mse: 1.1200\n",
            "Epoch 100/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.1195 - mse: 1.1195\n",
            "Epoch 101/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.1190 - mse: 1.1190\n",
            "Epoch 102/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.1186 - mse: 1.1186\n",
            "Epoch 103/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.1181 - mse: 1.1181\n",
            "Epoch 104/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.1176 - mse: 1.1176\n",
            "Epoch 105/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.1171 - mse: 1.1171\n",
            "Epoch 106/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.1167 - mse: 1.1167\n",
            "Epoch 107/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.1162 - mse: 1.1162\n",
            "Epoch 108/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.1157 - mse: 1.1157\n",
            "Epoch 109/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.1153 - mse: 1.1153\n",
            "Epoch 110/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.1148 - mse: 1.1148\n",
            "Epoch 111/300\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1144 - mse: 1.1144\n",
            "Epoch 112/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.1139 - mse: 1.1139\n",
            "Epoch 113/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.1135 - mse: 1.1135\n",
            "Epoch 114/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1130 - mse: 1.1130\n",
            "Epoch 115/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.1126 - mse: 1.1126\n",
            "Epoch 116/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.1122 - mse: 1.1122\n",
            "Epoch 117/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.1117 - mse: 1.1117\n",
            "Epoch 118/300\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.1113 - mse: 1.1113\n",
            "Epoch 119/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.1109 - mse: 1.1109\n",
            "Epoch 120/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.1105 - mse: 1.1105\n",
            "Epoch 121/300\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.1101 - mse: 1.1101\n",
            "Epoch 122/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.1096 - mse: 1.1096\n",
            "Epoch 123/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.1092 - mse: 1.1092\n",
            "Epoch 124/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 1.1088 - mse: 1.1088\n",
            "Epoch 125/300\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 1.1084 - mse: 1.1084\n",
            "Epoch 126/300\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.1080 - mse: 1.1080\n",
            "Epoch 127/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.1076 - mse: 1.1076\n",
            "Epoch 128/300\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.1072 - mse: 1.1072\n",
            "Epoch 129/300\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1069 - mse: 1.1069\n",
            "Epoch 130/300\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1065 - mse: 1.1065\n",
            "Epoch 131/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.1061 - mse: 1.1061\n",
            "Epoch 132/300\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.1057 - mse: 1.1057\n",
            "Epoch 133/300\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.1053 - mse: 1.1053\n",
            "Epoch 134/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.1050 - mse: 1.1050\n",
            "Epoch 135/300\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 1.1046 - mse: 1.1046\n",
            "Epoch 136/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.1042 - mse: 1.1042\n",
            "Epoch 137/300\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1039 - mse: 1.1039\n",
            "Epoch 138/300\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1035 - mse: 1.1035\n",
            "Epoch 139/300\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1031 - mse: 1.1031\n",
            "Epoch 140/300\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.1028 - mse: 1.1028\n",
            "Epoch 141/300\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1024 - mse: 1.1024\n",
            "Epoch 142/300\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1021 - mse: 1.1021\n",
            "Epoch 143/300\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1017 - mse: 1.1017\n",
            "Epoch 144/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.1014 - mse: 1.1014\n",
            "Epoch 145/300\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1011 - mse: 1.1011\n",
            "Epoch 146/300\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1007 - mse: 1.1007\n",
            "Epoch 147/300\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1004 - mse: 1.1004\n",
            "Epoch 148/300\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1001 - mse: 1.1001\n",
            "Epoch 149/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.0997 - mse: 1.0997\n",
            "Epoch 150/300\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0994 - mse: 1.0994\n",
            "Epoch 151/300\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0991 - mse: 1.0991\n",
            "Epoch 152/300\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0988 - mse: 1.0988\n",
            "Epoch 153/300\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0984 - mse: 1.0984\n",
            "Epoch 154/300\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.0981 - mse: 1.0981\n",
            "Epoch 155/300\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0978 - mse: 1.0978\n",
            "Epoch 156/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0975 - mse: 1.0975\n",
            "Epoch 157/300\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.0972 - mse: 1.0972\n",
            "Epoch 158/300\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0969 - mse: 1.0969\n",
            "Epoch 159/300\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0966 - mse: 1.0966\n",
            "Epoch 160/300\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0963 - mse: 1.0963\n",
            "Epoch 161/300\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0960 - mse: 1.0960\n",
            "Epoch 162/300\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0957 - mse: 1.0957\n",
            "Epoch 163/300\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0954 - mse: 1.0954\n",
            "Epoch 164/300\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0951 - mse: 1.0951\n",
            "Epoch 165/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 1.0948 - mse: 1.0948\n",
            "Epoch 166/300\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 1.0945 - mse: 1.0945\n",
            "Epoch 167/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.0942 - mse: 1.0942\n",
            "Epoch 168/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.0940 - mse: 1.0940\n",
            "Epoch 169/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0937 - mse: 1.0937\n",
            "Epoch 170/300\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0934 - mse: 1.0934\n",
            "Epoch 171/300\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0931 - mse: 1.0931\n",
            "Epoch 172/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.0929 - mse: 1.0929\n",
            "Epoch 173/300\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0926 - mse: 1.0926\n",
            "Epoch 174/300\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0923 - mse: 1.0923\n",
            "Epoch 175/300\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0921 - mse: 1.0921\n",
            "Epoch 176/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 1.0918 - mse: 1.0918\n",
            "Epoch 177/300\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.0915 - mse: 1.0915\n",
            "Epoch 178/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0913 - mse: 1.0913\n",
            "Epoch 179/300\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0910 - mse: 1.0910\n",
            "Epoch 180/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.0908 - mse: 1.0908\n",
            "Epoch 181/300\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0905 - mse: 1.0905\n",
            "Epoch 182/300\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0902 - mse: 1.0902\n",
            "Epoch 183/300\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0900 - mse: 1.0900\n",
            "Epoch 184/300\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0898 - mse: 1.0898\n",
            "Epoch 185/300\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0895 - mse: 1.0895\n",
            "Epoch 186/300\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0893 - mse: 1.0893\n",
            "Epoch 187/300\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.0890 - mse: 1.0890\n",
            "Epoch 188/300\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.0888 - mse: 1.0888\n",
            "Epoch 189/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.0885 - mse: 1.0885\n",
            "Epoch 190/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.0883 - mse: 1.0883\n",
            "Epoch 191/300\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.0881 - mse: 1.0881\n",
            "Epoch 192/300\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.0878 - mse: 1.0878\n",
            "Epoch 193/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.0876 - mse: 1.0876\n",
            "Epoch 194/300\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0874 - mse: 1.0874\n",
            "Epoch 195/300\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0872 - mse: 1.0872\n",
            "Epoch 196/300\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0869 - mse: 1.0869\n",
            "Epoch 197/300\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0867 - mse: 1.0867\n",
            "Epoch 198/300\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0865 - mse: 1.0865\n",
            "Epoch 199/300\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0863 - mse: 1.0863\n",
            "Epoch 200/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.0861 - mse: 1.0861\n",
            "Epoch 201/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.0859 - mse: 1.0859\n",
            "Epoch 202/300\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0856 - mse: 1.0856\n",
            "Epoch 203/300\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0854 - mse: 1.0854\n",
            "Epoch 204/300\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0852 - mse: 1.0852\n",
            "Epoch 205/300\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0850 - mse: 1.0850\n",
            "Epoch 206/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0848 - mse: 1.0848\n",
            "Epoch 207/300\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0846 - mse: 1.0846\n",
            "Epoch 208/300\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0844 - mse: 1.0844\n",
            "Epoch 209/300\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0842 - mse: 1.0842\n",
            "Epoch 210/300\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0840 - mse: 1.0840\n",
            "Epoch 211/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0838 - mse: 1.0838\n",
            "Epoch 212/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.0836 - mse: 1.0836\n",
            "Epoch 213/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.0834 - mse: 1.0834\n",
            "Epoch 214/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0832 - mse: 1.0832\n",
            "Epoch 215/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0830 - mse: 1.0830\n",
            "Epoch 216/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0828 - mse: 1.0828\n",
            "Epoch 217/300\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0826 - mse: 1.0826\n",
            "Epoch 218/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0825 - mse: 1.0825\n",
            "Epoch 219/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0823 - mse: 1.0823\n",
            "Epoch 220/300\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.0821 - mse: 1.0821\n",
            "Epoch 221/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0819 - mse: 1.0819\n",
            "Epoch 222/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0817 - mse: 1.0817\n",
            "Epoch 223/300\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.0815 - mse: 1.0815\n",
            "Epoch 224/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0814 - mse: 1.0814\n",
            "Epoch 225/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0812 - mse: 1.0812\n",
            "Epoch 226/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0810 - mse: 1.0810\n",
            "Epoch 227/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0808 - mse: 1.0808\n",
            "Epoch 228/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0807 - mse: 1.0807\n",
            "Epoch 229/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0805 - mse: 1.0805\n",
            "Epoch 230/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0803 - mse: 1.0803\n",
            "Epoch 231/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.0802 - mse: 1.0802\n",
            "Epoch 232/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0800 - mse: 1.0800\n",
            "Epoch 233/300\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0798 - mse: 1.0798\n",
            "Epoch 234/300\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.0797 - mse: 1.0797\n",
            "Epoch 235/300\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.0795 - mse: 1.0795\n",
            "Epoch 236/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.0793 - mse: 1.0793\n",
            "Epoch 237/300\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.0792 - mse: 1.0792\n",
            "Epoch 238/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0790 - mse: 1.0790\n",
            "Epoch 239/300\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 1.0789 - mse: 1.0789\n",
            "Epoch 240/300\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0787 - mse: 1.0787\n",
            "Epoch 241/300\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0786 - mse: 1.0786\n",
            "Epoch 242/300\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0784 - mse: 1.0784\n",
            "Epoch 243/300\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0783 - mse: 1.0783\n",
            "Epoch 244/300\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0781 - mse: 1.0781\n",
            "Epoch 245/300\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 1.0780 - mse: 1.0780\n",
            "Epoch 246/300\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0778 - mse: 1.0778\n",
            "Epoch 247/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0777 - mse: 1.0777\n",
            "Epoch 248/300\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0775 - mse: 1.0775\n",
            "Epoch 249/300\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0774 - mse: 1.0774\n",
            "Epoch 250/300\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0772 - mse: 1.0772\n",
            "Epoch 251/300\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0771 - mse: 1.0771\n",
            "Epoch 252/300\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.0769 - mse: 1.0769\n",
            "Epoch 253/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.0768 - mse: 1.0768\n",
            "Epoch 254/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.0767 - mse: 1.0767\n",
            "Epoch 255/300\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.0765 - mse: 1.0765\n",
            "Epoch 256/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.0764 - mse: 1.0764\n",
            "Epoch 257/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.0763 - mse: 1.0763\n",
            "Epoch 258/300\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.0761 - mse: 1.0761\n",
            "Epoch 259/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.0760 - mse: 1.0760\n",
            "Epoch 260/300\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0759 - mse: 1.0759\n",
            "Epoch 261/300\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0757 - mse: 1.0757\n",
            "Epoch 262/300\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0756 - mse: 1.0756\n",
            "Epoch 263/300\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0755 - mse: 1.0755\n",
            "Epoch 264/300\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0753 - mse: 1.0753\n",
            "Epoch 265/300\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0752 - mse: 1.0752\n",
            "Epoch 266/300\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0751 - mse: 1.0751\n",
            "Epoch 267/300\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.0750 - mse: 1.0750\n",
            "Epoch 268/300\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0748 - mse: 1.0748\n",
            "Epoch 269/300\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0747 - mse: 1.0747\n",
            "Epoch 270/300\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0746 - mse: 1.0746\n",
            "Epoch 271/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0745 - mse: 1.0745\n",
            "Epoch 272/300\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0744 - mse: 1.0744\n",
            "Epoch 273/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.0742 - mse: 1.0742\n",
            "Epoch 274/300\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 1.0741 - mse: 1.0741\n",
            "Epoch 275/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.0740 - mse: 1.0740\n",
            "Epoch 276/300\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.0739 - mse: 1.0739\n",
            "Epoch 277/300\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0738 - mse: 1.0738\n",
            "Epoch 278/300\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0737 - mse: 1.0737\n",
            "Epoch 279/300\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0735 - mse: 1.0735\n",
            "Epoch 280/300\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0734 - mse: 1.0734\n",
            "Epoch 281/300\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0733 - mse: 1.0733\n",
            "Epoch 282/300\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0732 - mse: 1.0732\n",
            "Epoch 283/300\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0731 - mse: 1.0731\n",
            "Epoch 284/300\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0730 - mse: 1.0730\n",
            "Epoch 285/300\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0729 - mse: 1.0729\n",
            "Epoch 286/300\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.0728 - mse: 1.0728\n",
            "Epoch 287/300\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.0727 - mse: 1.0727\n",
            "Epoch 288/300\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.0726 - mse: 1.0726\n",
            "Epoch 289/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0725 - mse: 1.0725\n",
            "Epoch 290/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0724 - mse: 1.0724\n",
            "Epoch 291/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.0723 - mse: 1.0723\n",
            "Epoch 292/300\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 1.0722 - mse: 1.0722\n",
            "Epoch 293/300\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.0721 - mse: 1.0721\n",
            "Epoch 294/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0720 - mse: 1.0720\n",
            "Epoch 295/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.0719 - mse: 1.0719\n",
            "Epoch 296/300\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0718 - mse: 1.0718\n",
            "Epoch 297/300\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.0717 - mse: 1.0717\n",
            "Epoch 298/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 1.0716 - mse: 1.0716\n",
            "Epoch 299/300\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0715 - mse: 1.0715\n",
            "Epoch 300/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0714 - mse: 1.0714\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f66decd4c50>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(x, model.predict(x), 'b', x, y, 'k.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "id": "P_F-w6qpMWpG",
        "outputId": "440a6303-061e-4105-aeea-91d2d464da9d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f66ddc3c490>,\n",
              " <matplotlib.lines.Line2D at 0x7f66ddbce750>]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.predict([9.5]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02W-io1SMY7r",
        "outputId": "c86eb7a7-bbac-44e8-8b05-2f1293af6439"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[102.17858]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "9시간을 공부하면 약 98.5점을 얻는대요"
      ],
      "metadata": {
        "id": "0Sv6emBLOW_D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "fAFuFs2FOP2R"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}